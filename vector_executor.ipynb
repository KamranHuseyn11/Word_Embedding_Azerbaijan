{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INFO\n",
    "\n",
    "--------------------------------------------------------------------------\n",
    "\n",
    "This script shows how to use stored vectors after training and some samples for intrinsic testing, word pair and word analogy testing \n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "\n",
    "Note: Keyedvectors module only supports Word2vec format. You have to transform glove vectors to\n",
    "Word2Vec format first in order to use them with this model \n",
    "\n",
    "-----------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loading word2vec\n",
    "\n",
    "model = KeyedVectors.load_word2vec_format( _your_vectors_, encoding =\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loading glove \n",
    "\n",
    "glove2word2vec(_your_glove_vectors_file_, _new_vectors_file_)\n",
    "model = KeyedVectors.load_word2vec_format(  _new_vectors_file_, encoding =\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------\n",
    "Some testing with model\n",
    "\n",
    "-------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('evin', 0.6946859359741211), ('mənzil', 0.6752898097038269), ('eveşik', 0.619435727596283)]\n"
     ]
    }
   ],
   "source": [
    "# word pairs\n",
    "print(model.most_similar(positive = [\"ev\"],topn=3) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-238994c76ef6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpositive\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"mende\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"sen\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnegative\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"men\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtopn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Word analogy,   mən for məndə, sən for ?  \n",
    "print(model.most_similar(positive = [\"məndə\",\"sən\"], negative = [\"mən\"],topn=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ata'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finiding most similiar word from a pool of words\n",
    "model.most_similar_to_given(\"ana\",[\"ağ\",\"süd\",\"qadın\",\"əli\",\"vəli\",\"baba\",\"və\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ana', 0.8326361775398254),\n",
       " ('uşaq', 0.6714300513267517),\n",
       " ('qadın', 0.6627384424209595),\n",
       " ('ata', 0.6251322031021118),\n",
       " ('uşaqların', 0.5814324617385864),\n",
       " ('körpə', 0.5662580132484436),\n",
       " ('gənc', 0.5546013116836548),\n",
       " ('ananın', 0.5372227430343628),\n",
       " ('doğma', 0.5336924195289612),\n",
       " ('dünyaya', 0.5297045111656189)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word analogy with other method\n",
    "\n",
    "model.similar_by_vector( model_glove.get_vector(\"ata\")  - model_glove.get_vector(\"kişi\") + model_glove.get_vector(\"qadın\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ana\n",
      "oğul\n",
      "atanın\n",
      "baba\n",
      "qız\n",
      "bromis\n",
      "ananın\n",
      "anam\n",
      "oğlum\n",
      "oğlan\n"
     ]
    }
   ],
   "source": [
    "# word pairs without probabilities \n",
    "for _tuple in model.most_similar(\"ata\"):\n",
    "    if (_tuple[1] > 0.60):\n",
    "        print(_tuple[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------\n",
    "\n",
    "Intrinsic Evaluation:\n",
    "\n",
    "you can test your model for semantic and syntactic analogies. to do this you need prepare questions.txt file and run it with following code   \n",
    "\n",
    "---------------------------------------\n",
    "\n",
    "It is recommended to build semantic and syntactic questions separately.\n",
    "for creating questions please refer to sample_questions.txt in the repository.\n",
    "\n",
    "-------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (f\" syntactic score: - {model.evaluate_word_analogies('questions_sytactic.txt')[0]}\")\n",
    "print (f\" semantic score: - {model.evaluate_word_analogies('questions_semantic.txt')[0]}\" ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for verbose results \n",
    "\n",
    "model.evaluate_word_analogies('questions_sytactic.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
